

py3Image = "h3abionet_org/py3plink"
gemmaImage="h3abionet_org/h3agwas-gemma"
latexImage="h3abionet_org/h3agwas-texlive"
swarmPort = '2376'
queue = 'batch'

manifest {
    homePage = 'http://github.com/h3abionet/h3agwas'
    description = 'GWAS Pipeline for H3Africa'
    mainScript = 'plink-qc.nf'
}


aws {
    accessKey =''
    secretKey =''
    region    ='eu-west-1'
}

cloud {
    imageId = "ami-710b9108"      // specify your AMI id here
    instanceType = "m4.xlarge"
    subnetId = "null"
    sharedStorageId   = "null"
    sharedStorageMount = "/mnt/shared"
    bootStorageSize = "20GB"     // Size of disk for images spawned
    //   instanceStorageMount = ""   // Set a common mount point for images
    //   instanceStorageDevice = ""  // Set a common block device for images
    autoscale {
        enabled = true
        maxInstances = 1
        terminateWhenIdle = true
    }

}


params {

    // Directories
    work_dir                = "/$PWD"
    input_dir               = "${params.work_dir}/input"
    output_dir              = "${params.work_dir}/output"
    scripts                 = "${params.work_dir}/scripts"
    output                  = "out"


    max_forks            = 95     
    // Data
    input_pat            = "sampleA"


    high_ld_regions_fname = ""
    sexinfo_available    = true
    cut_het_high         = 0.343
    cut_het_low           = 0.15
    cut_diff_miss         = "0.05"
    cut_maf                = "0.01"
    cut_mind              = "0.02"
    cut_geno              = 0.01
    cut_hwe               = 0.008
    pi_hat                = 0.11
    super_pi_hat 	  = 0.7
    f_lo_male             = 0.8 // default for F-sex check -- >= means male
    f_hi_female           = 0.2 //  <= means female
    case_control         = "${params.input_dir}/sample.phe"
    case_control_col     = "PHE"


    phenotype = 0
    pheno_col = "all"
    batch = 0
    batch_col = 0

    samplesize           = 0  // How many individuals in each genotype report 0=ALL
    strandreport         =""
    manifest             =  ""
    idpat                =  0  // or "(\\w+)-DNA_(\\w+)_.*" or ".*_(.*)"


    // Needed for topbottom.nf -- uncomment and put in details
    // reference        = ""
    // output_align     = ""
    // samplesheet      = ""
    // chipdescription  = ""  

    accessKey            = ""
    secretKey            = ""
    region               = "eu-west-1"
    AMI                  = "ami-710b9108"
    instanceType         = "m4.xlarge"
    bootStorageSize      = "20GB"
    maxInstances         = "1"

    plink_mem_req        = "750MB"
    other_mem_req        = "750MB"
    big_time             = '12h'
    sharedStorageMount   = "/mnt/shared"
    gemma_num_cores     =  8
    max_plink_cores      = 4


}
profiles {

    // For execution on a local machine, no containerization. -- Default
    standard {
        process.executor = 'local'
    }

    // For execution on a PBS scheduler, no containerization.
    pbs {
        process.executor = 'pbs'
        process.queue = queue
    }

    // For execution on a PBS scheduler with containerization.
    pbsDocker {

        process.executor = 'pbs'
	container = py3Image
        process.executor = 'local'
        process.$produceReports.container  =latexImage
        process.$computeTest.container     = "$gemmaImage"

        docker.remove      = true
        docker.runOptions  = '--rm'
        docker.registry    = 'quay.io'
        docker.enabled     = true
        docker.temp        = 'auto'
        docker.fixOwnership= true
    }

    // Execute pipeline with Docker locally
    docker {
        process.executor = 'local'
	process.container = py3Image
        process.$produceReports.container  =latexImage
        process.$computeTest.container     = "$gemmaImage"

        docker.remove      = true
        docker.runOptions  = '--rm'
              docker.registry    = 'quay.io'
        docker.enabled     = true
        docker.temp        = 'auto'
        docker.fixOwnership= true
        docker.process.executor = 'local'
    }

    dockerpbs {
        process.executor = 'pbs'
	process.container = py3Image
        process.$produceReports.container  ="$latexImage"
        process.$computeTest.container     = "$gemmaImage"

        docker.remove      = true
        docker.runOptions  = '--rm'
              docker.registry    = 'quay.io'
        docker.enabled     = true
        docker.temp        = 'auto'
        docker.fixOwnership= true
        docker.process.executor = 'local'
        docker.fixOwnership = true
    }


    // Execute pipeline with Docker Swarm setup
    dockerSwarm {

	process.container = py3Image
        process.$produceReports.container  ="$latexImage"
        process.$computeTest.container     = "$gemmaImage"


        docker.remove      = true
        docker.runOptions  = '--rm'
        docker.registry    = 'quay.io'
        docker.enabled     = true
        docker.temp        = 'auto'
        docker.fixOwnership= true
        docker.process.executor = 'local'
        docker.engineOptions = "-H :$swarmPort"
    }


    singularity {

        sg_py3Image = "/home/scott/py3plink.img"
        sg_latexImage = "/home/scott/h3agwas-texlive.img"


        enabled = true
        process.executor = 'pbs'
        process.queue = queue
        container = sg_py3Image
        process.$produceReports.container  = sg_latexImage

     }

}


timeline { 
    enabled=true
    file = "nextflow_reports/timeline.html"
}

report {
    enabled = true
    file = "nextflow_reports/report.html"
}
