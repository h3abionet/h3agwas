plugins {
  id 'nf-azure'
}



py3Image = "quay.io/h3abionet_org/py3plink"
gemmaImage="quay.io/h3abionet_org/py3plink"
boltImage="quay.io/h3abionet_org/py3fastlmm"
latexImage="quay.io/h3abionet_org/h3agwas-texlive"
py3saige="quay.io/h3abionet_org/py3saige"
gctaImage="quay.io/h3abionet_org/gcta"
MetaAnImage="quay.io/h3abionet_org/py3metagwas"
fastlmmImage="quay.io/h3abionet_org/py3fastlmm"
ldscImage="quay.io/h3abionet_org/py2ldsc"
rImage="quay.io/h3abionet_org/py3rproject"
swarmPort = '2376'
queue = 'batch'

manifest {
    homePage = 'http://github.com/h3abionet/h3agwas'
    description = 'GWAS Pipeline for H3Africa'
    mainScript = 'main.nf'
}


aws {
    accessKey =''
    secretKey =''
    region    ='eu-west-1'
}

cloud {
    imageId = "ami-710b9108"      // specify your AMI id here
    instanceType = "m4.xlarge"
    subnetId = "null"
    sharedStorageId   = "null"
    sharedStorageMount = "/mnt/shared"
    bootStorageSize = "20GB"     // Size of disk for images spawned
    //   instanceStorageMount = ""   // Set a common mount point for images
    //   instanceStorageDevice = ""  // Set a common block device for images
    autoscale {
        enabled = true
        maxInstances = 1
        terminateWhenIdle = true
    }

}


params {

    // Directories
    work_dir                = "/$PWD"
    input_dir               = ""
    output_dir              = "${params.work_dir}/output"
    scripts                 = "${params.work_dir}/scripts"
    output                  = "out"


    max_forks            = 95     
    // Data
    phenotype = 0

    samplesize           = 0  // How many individuals in each genotype report 0=ALL


    accessKey            = ""
    secretKey            = ""
    region               = "eu-west-1"
    AMI                  = "ami-710b9108"
    instanceType         = "m4.xlarge"
    bootStorageSize      = "20GB"
    maxInstances         = "1"

    plink_mem_req        = "750MB"
    other_mem_req        = "750MB"
    big_time             = '1000h'
    sharedStorageMount   = "/mnt/shared"
    max_plink_cores      = 4


}
profiles {

    // For execution on a local machine, no containerization. -- Default
    standard {
        process.executor = 'local'
    }

    slurm {
       process.executor = 'slurm'
       process.queue = queue
    }

    awsbatch {
         process.executor = "awsbatch"
         aws.region    ='us-east-1'
         aws.uploadStorageClass = 'ONEZONE_IA'
         process.queue = 'h3a'
    }




    // Execute pipeline with Docker locally
    docker {
        process.executor = 'local'
        docker.remove      = true
        docker.runOptions  = '--rm'
        docker.registry    = 'quay.io'
        docker.enabled     = true
        docker.temp        = 'auto'
        docker.fixOwnership= true
        docker.process.executor = 'local'
    }


    // Execute pipeline with Docker Swarm setup
    dockerSwarm {
        docker.remove      = true
        docker.runOptions  = '--rm'
        docker.registry    = 'quay.io'
        docker.enabled     = true
        docker.temp        = 'auto'
        docker.fixOwnership= true
        docker.process.executor = 'local'
        docker.engineOptions = "-H :$swarmPort"
    }

    // For execution on a PBS scheduler, no containerization.
    pbs {
        process.executor = 'pbs'
        process.queue = queue
    }


    // For execution on a PBS scheduler with containerization.
    pbsDocker {

        process.executor = 'pbs'
        docker.remove      = true
        docker.runOptions  = '--rm'
        docker.registry    = 'quay.io'
        docker.enabled     = true
        docker.temp        = 'auto'
        docker.fixOwnership= true
    }


    // For execution on a SLURM scheduler, no containerization.
    slurm {
        process.executor = 'slurm'
        process.queue = queue
    }


    // For execution on a PBS scheduler with containerisation.
    slurmDocker {
        process.executor = 'slurm'
        docker.remove      = true
        docker.runOptions  = '--rm'
        docker.registry    = 'quay.io'
        docker.enabled     = true
        docker.temp        = 'auto'
        docker.fixOwnership= true
    }



    singularity {
        singularity.cacheDir = "${HOME}/.singularity"
        singularity.autoMounts = true
        singularity.enabled = true
        process.executor = 'local'
     }

    // For execution on a SLURM scheduler with singularity
    slurmSingularity {
        singularity.cacheDir = "${HOME}/.singularity"
        process.executor = 'slurm'
        singularity.autoMounts = true
        singularity.enabled = true
        singularity.runOption = "--cleanenv"
        process.queue = queue

    }

    slurmDocker {
        process.executor = 'slurm'
        process.queue = queue
        docker.remove      = true
        docker.runOptions  = '--rm'
        docker.registry    = 'quay.io'
        docker.enabled     = true
        docker.temp        = 'auto'
        docker.fixOwnership= true

    }
    // For execution on a PBS scheduler, no containerization.
    pbs {
        process.executor = 'pbs'
        process.queue = queue
    }


    // For execution on a PBS scheduler with containerization.
    pbsDocker {

        process.executor = 'pbs'
        docker.remove      = true
        docker.runOptions  = '--rm'
        docker.registry    = 'quay.io'
        docker.enabled     = true
        docker.temp        = 'auto'
        docker.fixOwnership= true
  } 
  
  // For execution on Azure Batch
  azurebatch {
        process.executor = 'azurebatch'
  }

}




process {
    container = py3Image

    withLabel:bigMem {
      memory = '8GB'
    }

    withLabel: gemma {
          container = gemmaImage
    }

    withLabel: latex {
          container = latexImage
    }
    withLabel: gcta{
          container = gctaImage
    }
    withLabel: metaanalyse {
          container = MetaAnImage
    }
    withLabel: bolt {
          container = boltImage
    }
    withLabel: R{
          container = rImage
    }

    withLabel : fastlmm{
          container = fastlmmImage
    }
    withLabel : saige{
          container = py3saige
    }
    withLabel : py2ldsc{
          container = ldscImage
    }

}

//timeline { 
//    enabled=true
//    file = "nextflow_reports/timeline.html"
//}

//report {
//    enabled = true
//    file = "nextflow_reports/report.html"
//}
